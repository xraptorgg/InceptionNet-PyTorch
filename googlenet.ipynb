{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms \n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device agnostic code\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataset\n",
    "\n",
    "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "\n",
    "# wget did not work for this kaggle notebook, hence i manually downloaded the dataset and uploaded it to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data\n",
    "\n",
    "TRAINING_PATH = \"tiny-imagenet-200/train\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_data = datasets.ImageFolder(root = TRAINING_PATH, transform = transform, target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading validation data\n",
    "\n",
    "VAL_PATH = \"tiny-imagenet-200/val\"\n",
    "\n",
    "\n",
    "with open(\"tiny-imagenet-200/val/val_annotations.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "val_dict = {}\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split('\\t')\n",
    "    val_dict[parts[0]] = parts[1]\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "    \n",
    "\n",
    "val_data = datasets.ImageFolder(root = VAL_PATH, transform = transform, target_transform = None)\n",
    "\n",
    "for i in range(len(val_data)):\n",
    "    img_path, _ = val_data.imgs[i]\n",
    "    img_name = os.path.basename(img_path)\n",
    "    val_data.imgs[i] = (img_path, training_data.classes.index(val_dict[img_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shapes\n",
    "\n",
    "print(f\"Length of training data = {len(training_data)}, Shape of Image = {training_data[0][0].shape}\")\n",
    "print(f\"Length of validation data = {len(val_data)}, Shape of Image = {val_data[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label mapping file\n",
    "with open(\"tiny-imagenet-200/words.txt\", 'r') as f:\n",
    "    class_names = f.readlines()\n",
    "    \n",
    "# mapping between WordNet IDs to class names\n",
    "class_dict = {}\n",
    "for line in class_names:\n",
    "    line = line.split('\\t')\n",
    "    class_dict[line[0]] = line[1].strip()\n",
    "    \n",
    "    \n",
    "# visualise\n",
    "torch.manual_seed(1234)\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "rows, cols = 3, 3\n",
    "for i in range(rows * cols):\n",
    "    rand_idx = torch.randint(0, len(training_data), size = [1]).item()\n",
    "    image, target = training_data[rand_idx]\n",
    "    fig.add_subplot(rows, cols, i + 1)\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(class_dict[training_data.classes[target]])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "training_dataloader = DataLoader(dataset = training_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_dataloader = DataLoader(dataset = val_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "training_images, training_targets = next(iter(training_dataloader))\n",
    "\n",
    "print(f\"Training images batch shape = {training_images.shape}\")\n",
    "print(f\"Training targets batch shape = {training_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InceptionNet model based on Inception V1 module\n",
    "# also known as the GoogLeNet\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = conv_block(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3)\n",
    "        self.maxpool_1 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.conv_2 = conv_block(in_channels = 64, out_channels = 192, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.maxpool_2 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.inception_3a = inception_module(in_channels = 192, out_1x1 = 64, in_3x3 = 96, out_3x3 = 128, in_5x5 = 16, out_5x5 = 32, out_maxpool = 32)\n",
    "        self.inception_3b = inception_module(in_channels = 256, out_1x1 = 128, in_3x3 = 128, out_3x3 = 192, in_5x5 = 32, out_5x5 = 96, out_maxpool = 64)\n",
    "        self.maxpool_3 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.inception_4a = inception_module(in_channels = 480, out_1x1 = 192, in_3x3 = 96, out_3x3 = 208, in_5x5 = 16, out_5x5 = 48, out_maxpool = 64)\n",
    "        self.inception_4b = inception_module(in_channels = 512, out_1x1 = 160, in_3x3 = 112, out_3x3 = 224, in_5x5 = 24, out_5x5 = 64, out_maxpool = 64)\n",
    "        self.inception_4c = inception_module(in_channels = 512, out_1x1 = 128, in_3x3 = 128, out_3x3 = 256, in_5x5 = 24, out_5x5 = 64, out_maxpool = 64)\n",
    "        self.inception_4d = inception_module(in_channels = 512, out_1x1 = 112, in_3x3 = 144, out_3x3 = 288, in_5x5 = 32, out_5x5 = 64, out_maxpool = 64)\n",
    "        self.inception_4e = inception_module(in_channels = 528, out_1x1 = 256, in_3x3 = 160, out_3x3 = 320, in_5x5 = 32, out_5x5 = 128, out_maxpool = 128)\n",
    "        self.maxpool_4 = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.inception_5a = inception_module(in_channels = 832, out_1x1 = 256, in_3x3 = 160, out_3x3 = 320, in_5x5 = 32, out_5x5 = 128, out_maxpool = 128)\n",
    "        self.inception_5b = inception_module(in_channels = 832, out_1x1 = 384, in_3x3 = 192, out_3x3 = 384, in_5x5 = 48, out_5x5 = 128, out_maxpool = 128)\n",
    "        self.avgpool_5 = nn.AvgPool2d(kernel_size = 7, stride = 1)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p = 0.4)\n",
    "        self.fc = nn.Linear(in_features = 1024, out_features = num_classes)\n",
    "\n",
    "\n",
    "\n",
    "        self.aux_1 = auxiliary_classifier(in_channels = 512, num_classes = num_classes)\n",
    "        self.aux_2 = auxiliary_classifier(in_channels = 528, num_classes = num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.maxpool_1(x)\n",
    "\n",
    "        x = self.conv_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "\n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        x = self.maxpool_3(x)\n",
    "\n",
    "        x = self.inception_4a(x)\n",
    "\n",
    "        if self.training:\n",
    "            aux1 = self.aux_1(x)\n",
    "\n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "\n",
    "        if self.training:\n",
    "            aux2 = self.aux_2(x)\n",
    "\n",
    "        x = self.inception_4e(x)\n",
    "        x = self.maxpool_4(x)\n",
    "\n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "        x = self.avgpool_5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self.training:\n",
    "            return aux1, aux2, x\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "\n",
    "class inception_module(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, in_3x3, out_3x3, in_5x5, out_5x5, out_maxpool):\n",
    "        super().__init__()\n",
    "\n",
    "        self.branch_1 = conv_block(in_channels = in_channels, out_channels = out_1x1, kernel_size = 1, stride = 1, padding = 0)\n",
    "\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            conv_block(in_channels = in_channels, out_channels = in_3x3, kernel_size = 1, stride = 1, padding = 0),\n",
    "            conv_block(in_channels = in_3x3, out_channels = out_3x3, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "\n",
    "        self.branch_3 = nn.Sequential(\n",
    "            conv_block(in_channels = in_channels, out_channels = in_5x5, kernel_size = 1, stride = 1, padding = 0),\n",
    "            conv_block(in_channels = in_5x5, out_channels = out_5x5, kernel_size = 5, stride = 1, padding = 2)\n",
    "        )\n",
    "\n",
    "        self.branch_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "            conv_block(in_channels = in_channels, out_channels = out_maxpool, kernel_size = 1, stride = 1, padding = 0)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [self.branch_1(x), self.branch_2(x), self.branch_3(x), self.branch_4(x)], 1\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "class auxiliary_classifier(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 5, stride = 3)\n",
    "        self.conv_1 = conv_block(in_channels = in_channels, out_channels = 128, kernel_size = 1, stride = 1, padding = 0)\n",
    "        self.fc1 = nn.Linear(in_features = 4 * 4 * 128, out_features = 1024)\n",
    "        self.fc2 = nn.Linear(in_features = 1024, out_features = num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.7)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avgpool(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride, padding = padding)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test metrics \n",
    "\n",
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "val_acc_values = []\n",
    "epoch_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "def model_train(epochs, model, train_dataloader, val_dataloader, loss_func, optimizer, scheduler):\n",
    "\n",
    "    # turn on training mode\n",
    "    model.train()\n",
    "\n",
    "    #check training device\n",
    "    print(f\"Training on {device}.\")\n",
    "\n",
    "    # loop through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}\\n-------------\")\n",
    "\n",
    "        # loop through each batch\n",
    "        train_loss, train_acc = 0, 0\n",
    "        total_steps = 1\n",
    "        for images, classes in train_dataloader:\n",
    "\n",
    "            #send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # computer forward pass\n",
    "            aux1, aux2, out = model(images)\n",
    "\n",
    "            # compute loss for main output\n",
    "            loss_out = loss_func(out, classes)\n",
    "            train_acc += accuracy_fn(y_true = classes, y_pred = out.argmax(dim=1))\n",
    "\n",
    "            # compute loss for auxiliary classifiers\n",
    "            loss_aux1 = loss_func(aux1, classes)\n",
    "            loss_aux2 = loss_func(aux2, classes)\n",
    "\n",
    "            # compute total loss\n",
    "            loss = loss_out + 0.3 * (loss_aux1 + loss_aux2)\n",
    "            train_loss += loss\n",
    "\n",
    "            # update weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = train_loss / total_steps\n",
    "            batch_acc = train_acc / total_steps\n",
    "\n",
    "            if total_steps % 10 == 0:\n",
    "                print(f\"Training Loss: {batch_loss:.5f} - Training Accuracy: {batch_acc:.5f}%\")\n",
    "\n",
    "            total_steps += 1\n",
    "\n",
    "        # learning rate decay\n",
    "        scheduler.step()\n",
    "\n",
    "        # performance on test set\n",
    "        # turn on inference mode\n",
    "        with torch.inference_mode():\n",
    "            # loop through each batch\n",
    "            total_val_loss, val_acc = 0, 0\n",
    "            for val_images, val_classes in val_dataloader:\n",
    "                # send data to device\n",
    "                val_images, val_classes = val_images.to(device), val_classes.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                y_val_pred = model(val_images)\n",
    "\n",
    "                # compute loss\n",
    "                val_loss = loss_func(y_val_pred, val_classes)\n",
    "                total_val_loss += val_loss\n",
    "                val_acc += accuracy_fn(y_true = val_classes, y_pred = y_val_pred.argmax(dim=1)\n",
    "                )\n",
    "            \n",
    "            total_val_loss /= len(val_dataloader)\n",
    "            val_acc /= len(val_dataloader)\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "\n",
    "        print(f\"[After {epoch + 1} epochs: Train Loss: {train_loss:.5f} - Train Accuracy: {train_acc:.5f}% - Validation Loss: {total_val_loss:.5f} - Validation Accuracy: {val_acc:.5f}%]\")\n",
    "\n",
    "        \n",
    "        train_loss_values.append(train_loss.item())\n",
    "        val_loss_values.append(total_val_loss.item())\n",
    "        val_acc_values.append(val_acc)\n",
    "        epoch_count.append(epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test loop\n",
    "\n",
    "def model_test(model, dataloader, loss_func):\n",
    "    # turn on test mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on inference mode\n",
    "    with torch.inference_mode():\n",
    "        # loop through each batch\n",
    "        test_loss, test_acc = 0, 0\n",
    "        for images, classes in dataloader:\n",
    "            # send data to device\n",
    "            images, classes = images.to(device), classes.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_func(y_pred, classes)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Loss: {test_loss:.5f} - Accuracy: {test_acc:.5f}%\")\n",
    "        return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric functions\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating model\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "googlenet = GoogLeNet(200).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "sgd = torch.optim.SGD(params = googlenet.parameters(), lr = LEARNING_RATE, momentum = 0.9)\n",
    "\n",
    "learning_decay = torch.optim.lr_scheduler.StepLR(optimizer = sgd, step_size = 8, gamma = 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "model_train(epochs = EPOCHS, model = googlenet, train_dataloader = training_dataloader, val_dataloader = val_dataloader, loss_func = loss_func, optimizer = sgd, scheduler = learning_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model\n",
    "\n",
    "accuracy = model_test(model = googlenet, dataloader = val_dataloader, loss_func = loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, train_loss_values, label = \"Train loss\")\n",
    "plt.plot(epoch_count, val_loss_values, label = \"Validation loss\")\n",
    "plt.title(\"Loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy curve\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plt.plot(epoch_count, val_acc_values, label = \"Accuracy\")\n",
    "plt.title(\"Accuracy curves\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "MODEL_NAME = \"GoogLeNet_\" + str(accuracy).replace(\".\", \"_\") + \".pth\"\n",
    "\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "print(f\"Saving GoogLeNet to {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj = alexnet.state_dict(), f = MODEL_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
